---
title: "report title"
author: '500331091'
date: "2022/5/6"
output: 
  html_document:
    fig_caption: yes
    number_sections: yes
    self_contained: yes
    theme: flatly
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
bibliography: packages.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setlocale(locale = "C")
library(GEOquery)
library(tidyverse)
library(limma)
library(VennDiagram)
library(cvTools)
library(e1071)
library(equatiomatic)
library(randomForest)
library(class)
library(naivebayes)
library(knitr)

load("datasets.rdata")

# gse1 <- getGEO("GSE51675")
# gse1 <- gse1$GSE51675_series_matrix.txt.gz
# 
# gse2 <- getGEO("GSE1563")
# gse2 <- gse2$GSE1563_series_matrix.txt.gz
# 
# gse3 <- getGEO("GSE46474")
# gse3 <- gse3$GSE46474_series_matrix.txt.gz
seed = 3888

knitr::write_bib(c(.packages()), "packages.bib")
```

```{r IDA}
boxplot(exprs(gse1))
boxplot(exprs(gse2))
boxplot(exprs(gse3))
```

```{r cleaning}
gse1_have_ID = gse1[-which(fData(gse1)$REFSEQ == ""),]
gse1_true_ID = sapply(strsplit(fData(gse1_have_ID)$REFSEQ, split = " "), "[[", 1)
gse1_cleaned = gse1_have_ID[!duplicated(gse1_true_ID),]
rownames(gse1_cleaned) = gse1_true_ID[!duplicated(gse1_true_ID)]

gse2_have_ID = gse2[-which(fData(gse2)$`RefSeq Transcript ID` == ""),]
gse2_true_ID = sapply(strsplit(fData(gse2_have_ID)$`RefSeq Transcript ID`, split = " "), "[[", 1)
gse2_cleaned = gse2_have_ID[!duplicated(gse2_true_ID),]
rownames(gse2_cleaned) = gse2_true_ID[!duplicated(gse2_true_ID)]

gse3_have_ID = gse3[-which(fData(gse3)$`RefSeq Transcript ID` == ""),]
gse3_true_ID = sapply(strsplit(fData(gse3_have_ID)$`RefSeq Transcript ID`, split = " "), "[[", 1)
gse3_cleaned = gse3_have_ID[!duplicated(gse3_true_ID),]
rownames(gse3_cleaned) = gse3_true_ID[!duplicated(gse3_true_ID)]

pdata1 <- pData(gse1_cleaned)
emat1 <- exprs(gse1_cleaned)# %>% scale()
outcome1 <- ifelse(grepl("rejection", pdata1$source_name_ch1), "Rejection", "Stable")

pdata2 <- pData(gse2_cleaned)
emat2 <- exprs(gse2_cleaned) %>% log2()# %>% scale()
outcome2 <- ifelse(grepl("acute rejection", pdata2$description), "Rejection", "Stable")

pdata3 <- pData(gse3_cleaned)
emat3 <- exprs(gse3_cleaned)# %>% scale()
outcome3 <- ifelse(grepl("AR", pdata3$title), "Rejection", "Stable")

age_cleaned = matrix(unlist(sapply(pdata2$description.1, strsplit, ": ")), nrow=2)[2,]
age_cleaned = ifelse(age_cleaned == "unknown", NA, age_cleaned)
sex_cleaned = matrix(unlist(sapply(pdata2$description.2, strsplit, ": ")), nrow=2)[2,]
clinical_df = pdata2 %>% 
  select(c("description.1", "description.2")) %>% 
  rename("age" = "description.1",
         "sex" = "description.2") %>% 
  mutate(age = as.numeric(age_cleaned) %>% scale(),
         sex = sex_cleaned)
```

```{r volcano, warning=F, message=F}
p_threshold = 0.05
logfc_threshold = 0.5

design1 <- model.matrix(~outcome1)
fit1 <- lmFit(emat1, design1)
fit1 <- eBayes(fit1)
df1 <- topTable(fit1, number = nrow(fit1), genelist = fData(gse1_cleaned)$GENE_SYMBOL)

df1$significant = "stable"
df1$significant[df1$logFC > logfc_threshold & df1$P.Value < p_threshold] = "up"
df1$significant[df1$logFC < -logfc_threshold & df1$P.Value < p_threshold] = "down"

ggplot(df1, aes(df1$logFC, -log10(df1$P.Value))) + 
    geom_point(aes(colour = significant),alpha = 0.4, size = 0.8) + xlim(-3,3) +
    scale_colour_manual(values = c("Blue", "Grey", "Red"))  + theme_classic() +
    geom_hline(yintercept = -log10(p_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    geom_vline(xintercept = c(-logfc_threshold,logfc_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    xlab("log2 fold change") + ylab("-log10 p-value")

design2 <- model.matrix(~outcome2)
fit2 <- lmFit(emat2, design2)
fit2 <- eBayes(fit2)
df2 <- topTable(fit2, number = nrow(fit2), genelist = fData(gse2_cleaned)$`Gene Symbol`)

df2$significant = "stable"
df2$significant[df2$logFC > logfc_threshold & df2$P.Value < p_threshold] = "up"
df2$significant[df2$logFC < -logfc_threshold & df2$P.Value < p_threshold] = "down"

ggplot(df2, aes(df2$logFC, -log10(df2$P.Value))) + 
    geom_point(aes(colour = significant),alpha = 0.4, size = 0.8) + 
    scale_colour_manual(values = c("Blue", "Grey", "Red"))  + theme_classic() +
    geom_hline(yintercept = -log10(p_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    geom_vline(xintercept = c(-logfc_threshold,logfc_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    xlab("log2 fold change") + ylab("-log10 p-value")

design3 <- model.matrix(~outcome3)
fit3 <- lmFit(emat3, design3)
fit3 <- eBayes(fit3)
df3 <- topTable(fit3, number = nrow(fit3), genelist = fData(gse3_cleaned)$`Gene Symbol`)

df3$significant = "stable"
df3$significant[df3$logFC > logfc_threshold & df3$P.Value < p_threshold] = "up"
df3$significant[df3$logFC < -logfc_threshold & df3$P.Value < p_threshold] = "down"

ggplot(df3, aes(df3$logFC, -log10(df3$P.Value))) + 
    geom_point(aes(colour = significant),alpha = 0.4, size = 0.8) + 
    scale_colour_manual(values = c("Blue", "Grey", "Red"))  + theme_classic() +
    geom_hline(yintercept = -log10(p_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    geom_vline(xintercept = c(-logfc_threshold,logfc_threshold), linetype = 2, alpha = 0.5, size = 0.6) +
    xlab("log2 fold change") + ylab("-log10 p-value")
```

```{r feature_selection, message=F}
set.seed(seed)

accuracy <- function(true, predicted) {
  # Calculates accuracy based on a vector of true labels and a vector of predictions
  return(sum(true == predicted)/length(true))
}

n_sim = 5
cvK = 5    # Number of CV folds
n_list = c()
genes_list = c()

for (i in 1:n_sim) {
    
  # cv_accuracy_folds = numeric(cvK)
  
  for (j in 1:cvK) {
    
    n = 0
    acc = 0
    acc_genes = c()
    
    for (top_n in seq(2, 50, 1)) {
      
      genes = rownames(topTable(fit2, number = top_n))
      combined_df = cbind(clinical_df, t(emat2[genes, ])) %>% 
        mutate(outcome = as.factor(outcome2)) %>% 
        drop_na() %>% 
        mutate(sex = as.factor(sex))
      for (i in 3: (length(combined_df) - 1)) {
        combined_df[, i] = combined_df[, i] / length(genes)
        mean = mean(combined_df[, i])
        sd = sd(combined_df[, i])
        combined_df[, i] = (combined_df[, i] - mean) / sd
      }
      
      cvSets = cvFolds(nrow(combined_df), cvK) # Folds object for cross-validation
      test_id = cvSets$subsets[cvSets$which == j]
      
      X_combined = combined_df %>% select(-outcome)
      y_combined = combined_df %>% pull(outcome)
      
      train = combined_df[-test_id,]
      X_test = X_combined[test_id,]
      y_test = y_combined[test_id]
      
      current_rf_fit = randomForest(x = train %>% select(-outcome), y = train$outcome)
      predictions = predict(current_rf_fit, X_test) # Predicting probability of stable
      current_accuracy = accuracy(y_test, predictions)
      
      if (current_accuracy > acc) {
        
        acc = current_accuracy
        n = top_n
        acc_genes = genes
        
      }
      
    }
    
    n_list = append(n_list, n)
    genes_list = append(genes_list, acc_genes)

  #   genes = rownames(topTable(fit2, number = n))
  #   combined_df = cbind(clinical_df, t(emat2[genes, ])) %>%
  #     mutate(outcome = as.factor(outcome2)) %>%
  #     drop_na() %>%
  #     mutate(sex = as.factor(sex))
  #   for (i in 3: (length(combined_df) - 1)) {
  #     combined_df[, i] = combined_df[, i] / length(genes)
  #     mean = mean(combined_df[, i])
  #     sd = sd(combined_df[, i])
  #     combined_df[, i] = (combined_df[, i] - mean) / sd
  #   }
  # 
  #   cvSets = cvFolds(nrow(combined_df), cvK)
  #   test_id = cvSets$subsets[cvSets$which == j]
  # 
  #   X_combined = combined_df %>% select(-outcome)
  #   y_combined = combined_df %>% pull(outcome)
  # 
  #   train = combined_df[-test_id,]
  #   X_test = X_combined[test_id,]
  #   y_test = y_combined[test_id]
  # 
  #   current_rf_fit = randomForest(x = train %>% select(-outcome), y = train$outcome)
  #   predictions = predict(current_rf_fit, X_test)
  #   cv_accuracy_folds[j] = accuracy(y_test, predictions)
  # 
  }
}
```

```{r feature_selection_results}
genes_table = data.frame(table(genes_list))
gene_symbols = fData(gse2_cleaned) %>% filter(rownames(fData(gse2_cleaned)) %in% unique(genes_list)) %>% select(`Gene Symbol`)
gene_symbols$`Gene Symbol` = sapply(strsplit(gene_symbols$`Gene Symbol`, split = " "), "[[", 1)
gene_symbols$`genes_list` = row.names(gene_symbols)
genes_plot_data = merge(genes_table, gene_symbols)
genes_plot_data = transform(genes_plot_data, `Gene Symbol` = reorder(`Gene Symbol`, -Freq))

ggplot(genes_plot_data, aes(x = Gene.Symbol, y = Freq)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Frequency of selected top genes in 5-fold CV across 5 repeats",
       x = "Gene Symbol", y = "Freq") +
  theme(plot.title = element_text(hjust = 0.5, size = 12),
        panel.border = element_rect(colour = "black", fill = NA, size = 1),
        axis.text = element_text(size=10),
        axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5))

n_table = data.frame(table(n_list))

ggplot(n_table, aes(x = n_list, y = Freq)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Frequency of selected number of top genes in 5-fold CV across 5 repeats",
       x = "Top gene number", y = "Freq") +
  theme(plot.title = element_text(hjust = 0.5, size = 12),
        panel.border = element_rect(colour = "black", fill = NA, size = 1))
```

```{r intersection, message=F}
top_n = 1100

genes1 = rownames(topTable(fit1, number = top_n))
genes2 = rownames(topTable(fit2, number = top_n))
genes3 = rownames(topTable(fit3, number = top_n))

venn_df = list()
venn_df$GSE51675 = genes1
venn_df$GSE1563 = genes2
venn_df$GSE46474 = genes3
color_list = c("#fb0007", "#139177", "#ed9e08", "#f56f08", "#4caecc")
fill_colors = color_list[1:length(venn_df)]
venn.diagram(venn_df, filename = "VennDiagram.tif", col = "white", fill = fill_colors, lwd = .5, cex = .5, cat.cex = .5, width = 1200, height = 1200)

top_genes = intersect(genes1, genes2)
top_genes = intersect(top_genes, genes3)
top_genes
fData(gse2_cleaned) %>% filter(rownames(fData(gse2_cleaned)) %in% top_genes) %>% select(`Gene Symbol`)
```

```{r training_testing_data}
combined_df = cbind(clinical_df, t(emat2[top_genes, ])) %>% 
  mutate(outcome = as.factor(outcome2)) %>% 
  drop_na() %>% 
  mutate(sex = as.factor(sex))

for (i in 3: (length(combined_df) - 1)) {
  combined_df[, i] = combined_df[, i] / length(top_genes)
  mean = mean(combined_df[, i])
  sd = sd(combined_df[, i])
  combined_df[, i] = (combined_df[, i] - mean) / sd
}
```

```{r repeated_cv, warning=F, message=F}
set.seed(3888)

accuracy <- function(true, predicted) {
  # Calculates accuracy based on a vector of true labels and a vector of predictions
  return(sum(true == predicted)/length(true))
}

sensitivity <- function(predicted, true) {
  predicted = factor(predicted, levels = c("Rejection", "Stable"))
  confusion = table(predicted, true)
  return(confusion[1,1]/(confusion[1,1]+confusion[2,1]))
}

specificity <- function(predicted, true) {
  predicted = factor(predicted, levels = c("Rejection", "Stable"))
  confusion = table(predicted, true)
  return(confusion[2,2]/(confusion[1,2]+confusion[2,2]))
}

X_combined = combined_df %>% select(-outcome)
y_combined = combined_df %>% pull(outcome)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats

cv_accuracy_lr = numeric(n_sim) # Vector to store averaged CV accuracies
cv_accuracy_rf = numeric(n_sim)
cv_accuracy_svm = numeric(n_sim)
cv_accuracy_nb = numeric(n_sim)
cv_accuracy_knn = numeric(n_sim)
# cv_accuracy_dt = numeric(n_sim)

cv_sensitivity_lr = numeric(n_sim)
cv_sensitivity_rf = numeric(n_sim)
cv_sensitivity_svm = numeric(n_sim)
cv_sensitivity_nb = numeric(n_sim)
cv_sensitivity_knn = numeric(n_sim)
# cv_sensitivity_dt = numeric(n_sim)

cv_specificity_lr = numeric(n_sim)
cv_specificity_rf = numeric(n_sim)
cv_specificity_svm = numeric(n_sim)
cv_specificity_nb = numeric(n_sim)
cv_specificity_knn = numeric(n_sim)
# cv_specificity_dt = numeric(n_sim)

for (i in 1:n_sim) {
  
  cvSets = cvFolds(nrow(combined_df), cvK) # Folds object for cross-validation
  
  cv_accuracy_folds_lr = numeric(cvK) # Vector to store accuracy for each fold
  cv_accuracy_folds_rf = numeric(cvK)
  cv_accuracy_folds_svm = numeric(cvK)
  cv_accuracy_folds_nb = numeric(cvK)
  cv_accuracy_folds_knn = numeric(cvK)
  # cv_accuracy_folds_dt = numeric(cvK)
  
  cv_sensitivity_folds_lr = numeric(cvK) # Vector to store sensitivity for each fold
  cv_sensitivity_folds_rf = numeric(cvK)
  cv_sensitivity_folds_svm = numeric(cvK)
  cv_sensitivity_folds_nb = numeric(cvK)
  cv_sensitivity_folds_knn = numeric(cvK)
  # cv_sensitivity_folds_dt = numeric(cvK)
  
  cv_specificity_folds_lr = numeric(cvK) # Vector to store specificity for each fold
  cv_specificity_folds_rf = numeric(cvK)
  cv_specificity_folds_svm = numeric(cvK)
  cv_specificity_folds_nb = numeric(cvK)
  cv_specificity_folds_knn = numeric(cvK)
  # cv_specificity_folds_dt = numeric(cvK)
  
  for (j in 1:cvK) {
    
    test_id = cvSets$subsets[cvSets$which == j]
    train = combined_df[-test_id,] # Don't split training set to match glm syntax
    X_test = X_combined[test_id,]
    y_test = y_combined[test_id]
    
    current_lr_fit = glm(outcome ~ ., data = train, family = binomial(link = "logit"), maxit = 10000)
    current_rf_fit = randomForest(x = train %>% select(-outcome), y = train$outcome)
    current_svm_fit = svm(train %>% select(-outcome) %>% select(-sex), train$outcome, kernel ="radial")
    current_nb_fit = naive_bayes(outcome ~ ., train)
    # current_dt_fit = rpart(outcome ~ ., train)
    
    
    predicted_probs = predict(current_lr_fit, X_test, type = "response")
    predictions = ifelse(round(predicted_probs) == 1, 
                         "Stable", "Rejection")
    cv_accuracy_folds_lr[j] = accuracy(y_test, predictions)
    cv_sensitivity_folds_lr[j] = sensitivity(predictions, y_test)
    cv_specificity_folds_lr[j] = specificity(predictions, y_test)
    
    predictions = predict(current_rf_fit, X_test)
    cv_accuracy_folds_rf[j] = accuracy(y_test, predictions)
    cv_sensitivity_folds_rf[j] = sensitivity(predictions, y_test)
    cv_specificity_folds_rf[j] = specificity(predictions, y_test)
    
    predictions = predict(current_svm_fit, X_test %>% select(-sex))
    cv_accuracy_folds_svm[j] = accuracy(y_test, predictions)
    cv_sensitivity_folds_svm[j] = sensitivity(predictions, y_test)
    cv_specificity_folds_svm[j] = specificity(predictions, y_test)

    predictions = predict(current_nb_fit, X_test)
    cv_accuracy_folds_nb[j] = accuracy(y_test, predictions)
    cv_sensitivity_folds_nb[j] = sensitivity(predictions, y_test)
    cv_specificity_folds_nb[j] = specificity(predictions, y_test)
    
    predictions = knn(train %>% select(-outcome) %>% select(-sex), test = X_test %>% select(-sex), cl = train$outcome, k = 6)
    cv_accuracy_folds_knn[j] = accuracy(y_test, predictions)
    cv_sensitivity_folds_knn[j] = sensitivity(predictions, y_test)
    cv_specificity_folds_knn[j] = specificity(predictions, y_test)
    
    # predictions = predict(current_dt_fit, X_test)
    # cv_accuracy_folds_dt[j] = accuracy(y_test, predictions)
  }
  
  cv_accuracy_lr[i] = mean(cv_accuracy_folds_lr)
  cv_accuracy_rf[i] = mean(cv_accuracy_folds_rf)
  cv_accuracy_svm[i] = mean(cv_accuracy_folds_svm)
  cv_accuracy_nb[i] = mean(cv_accuracy_folds_nb)
  cv_accuracy_knn[i] = mean(cv_accuracy_folds_knn)
  # cv_accuracy_dt[i] = mean(cv_accuracy_folds_dt)
  
  cv_sensitivity_lr[i] = mean(cv_sensitivity_folds_lr)
  cv_sensitivity_rf[i] = mean(cv_sensitivity_folds_rf)
  cv_sensitivity_svm[i] = mean(cv_sensitivity_folds_svm)
  cv_sensitivity_nb[i] = mean(cv_sensitivity_folds_nb)
  cv_sensitivity_knn[i] = mean(cv_sensitivity_folds_knn)
  # cv_sensitivity_dt[i] = mean(cv_sensitivity_folds_dt)

  cv_specificity_lr[i] = mean(cv_specificity_folds_lr)
  cv_specificity_rf[i] = mean(cv_specificity_folds_rf)
  cv_specificity_svm[i] = mean(cv_specificity_folds_svm)
  cv_specificity_nb[i] = mean(cv_specificity_folds_nb)
  cv_specificity_knn[i] = mean(cv_specificity_folds_knn)
  # cv_specificity_dt[i] = mean(cv_specificity_folds_dt)
  
}

df_lr = cbind(Performance = cv_accuracy_lr, Classifier = "Weighted Logistic", Type = "Accuracy")
df_rf = cbind(Performance = cv_accuracy_rf, Classifier = "Random Forest", Type = "Accuracy")
df_svm = cbind(Performance = cv_accuracy_svm, Classifier = "Support Vector Machine", Type = "Accuracy")
df_nb = cbind(Performance = cv_accuracy_nb, Classifier = "Naive Bayes", Type = "Accuracy")
df_knn = cbind(Performance = cv_accuracy_knn, Classifier = "6-Nearest Neighbor", Type = "Accuracy")

df2_lr = cbind(Performance = cv_sensitivity_lr, Classifier = "Weighted Logistic", Type = "Sensitivity")
df2_rf = cbind(Performance = cv_sensitivity_rf, Classifier = "Random Forest", Type = "Sensitivity")
df2_svm = cbind(Performance = cv_sensitivity_svm, Classifier = "Support Vector Machine", Type = "Sensitivity")
df2_nb = cbind(Performance = cv_sensitivity_nb, Classifier = "Naive Bayes", Type = "Sensitivity")
df2_knn = cbind(Performance = cv_sensitivity_knn, Classifier = "6-Nearest Neighbor", Type = "Sensitivity")

df3_lr = cbind(Performance = cv_specificity_lr, Classifier = "Weighted Logistic", Type = "Specificity")
df3_rf = cbind(Performance = cv_specificity_rf, Classifier = "Random Forest", Type = "Specificity")
df3_svm = cbind(Performance = cv_specificity_svm, Classifier = "Support Vector Machine", Type = "Specificity")
df3_nb = cbind(Performance = cv_specificity_nb, Classifier = "Naive Bayes", Type = "Specificity")
df3_knn = cbind(Performance = cv_specificity_knn, Classifier = "6-Nearest Neighbor", Type = "Specificity")

df_classifier_cv = data.frame(rbind(df_lr, df_rf, df_svm, df_nb, df_knn, df2_lr, df2_rf, df2_svm, df2_nb, df2_knn, df3_lr, df3_rf, df3_svm, df3_nb, df3_knn))
df_classifier_cv$Classifier = factor(df_classifier_cv$Classifier)
df_classifier_cv$Type = factor(df_classifier_cv$Type)
df_classifier_cv$Performance = as.numeric(df_classifier_cv$Performance)

ggplot(df_classifier_cv, aes(Classifier, Performance))+
  stat_boxplot(aes(fill=Type), geom="errorbar", width=0.1, size=0.5, position=position_dodge(0.6), color="steelblue")+
  geom_boxplot(aes(fill=Type),
               position=position_dodge(0.6),
               size=0.5,
               width=0.5,
               color="steelblue",
               outlier.color = "steelblue",
               outlier.fill = "indianred2",
               outlier.shape = 19,
               outlier.size = 1,
               outlier.stroke = 0.5,
               outlier.alpha = 45,
               notch = F,
               notchwidth = 0.5)+
  theme(axis.title = element_text(size=18),
        axis.text = element_text(size=10),
        axis.text.x = element_text(angle = 0, vjust = 0.5, hjust = 0.5)) + 
  labs(title = "Distribution of mean 5-fold CV performances across 50 repeats") + 
  coord_flip()
```

```{r independent_datasets_performance, warning=F}
final_nb = naive_bayes(outcome ~ ., combined_df)
final_lr = glm(outcome ~ ., data = combined_df, family = binomial(link = "logit"), maxit = 10000)

X_test1 = pdata1 %>% 
  select(c("age:ch1", "gender:ch1")) %>% 
  rename("age" = "age:ch1",
         "sex" = "gender:ch1") %>% 
  mutate(age = as.numeric(age) %>% scale(),
         sex = as.factor(sex))
X_test1 = cbind(X_test1, t(emat1[top_genes, ]))
for (i in 3: (length(X_test1))) {
  X_test1[, i] = X_test1[, i] / length(top_genes)
  mean = mean(X_test1[, i])
  sd = sd(X_test1[, i])
  X_test1[, i] = (X_test1[, i] - mean) / sd
}
y_test1 = as.factor(outcome1)

X_test3 = pdata3 %>% 
  select(c("age_tx:ch1", "Sex:ch1")) %>% 
  rename("age" = "age_tx:ch1",
         "sex" = "Sex:ch1") %>% 
  mutate(age = as.numeric(age) %>% scale(),
         sex = as.factor(ifelse(sex == "F", "Female", "Male")))
X_test3 = cbind(X_test3, t(emat3[top_genes, ]))
for (i in 3: (length(X_test3))) {
  X_test3[, i] = X_test3[, i] / length(top_genes)
  mean = mean(X_test3[, i])
  sd = sd(X_test3[, i])
  X_test3[, i] = (X_test3[, i] - mean) / sd
}
y_test3 = as.factor(outcome3)

# predictions1 = predict(final_model, X_test1)
predicted_probs1 = predict(final_lr, X_test1, type = "response")
predictions1 = ifelse(round(predicted_probs1) == 1, "Stable", "Rejection")
tb1 = table(Predictions = predictions1, Class = y_test1)
# tb1 %>% kable(caption = "Confusion table when testing on GSE51675")

performance1 = data.frame(Accuracy = (tb1[1,1]+tb1[2,2])/(sum(tb1)), Sensitivity = (tb1[1,1])/(sum(tb1[,1])), Specificity = (tb1[2,2])/(sum(tb1[,2])))
# performance1 %>% kable(caption = "Performance evaluation on GSE51675", digits = 2)

# predictions3 = predict(final_model, X_test3)
predicted_probs3 = predict(final_lr, X_test3, type = "response")
predictions3 = ifelse(round(predicted_probs3) == 1, "Stable", "Rejection")
tb3 = table(Predictions = predictions3, Class = y_test3)
# tb3 %>% kable(caption = "Confusion table when testing on GSE46474")

performance3 = data.frame(Accuracy = (tb3[1,1]+tb3[2,2])/(sum(tb3)), Sensitivity = (tb3[1,1])/(sum(tb3[,1])), Specificity = (tb3[2,2])/(sum(tb3[,2])))
# performance3 %>% kable(caption = "Performance evaluation on GSE46474", digits = 2)

df_lr = rbind(GSE51675.LR = performance1, GSE46474.LR = performance3)


predictions1 = predict(final_nb, X_test1)
# predicted_probs1 = predict(final_lr, X_test1, type = "response")
# predictions1 = ifelse(round(predicted_probs1) == 1, "Stable", "Rejection")
tb1 = table(Predictions = predictions1, Class = y_test1)
# tb1 %>% kable(caption = "Confusion table when testing on GSE51675")

performance1 = data.frame(Accuracy = (tb1[1,1]+tb1[2,2])/(sum(tb1)), Sensitivity = (tb1[1,1])/(sum(tb1[,1])), Specificity = (tb1[2,2])/(sum(tb1[,2])))
# performance1 %>% kable(caption = "Performance evaluation on GSE51675", digits = 2)

predictions3 = predict(final_nb, X_test3)
# predicted_probs3 = predict(final_lr, X_test3, type = "response")
# predictions3 = ifelse(round(predicted_probs3) == 1, "Stable", "Rejection")
tb3 = table(Predictions = predictions3, Class = y_test3)
# tb3 %>% kable(caption = "Confusion table when testing on GSE46474")

performance3 = data.frame(Accuracy = (tb3[1,1]+tb3[2,2])/(sum(tb3)), Sensitivity = (tb3[1,1])/(sum(tb3[,1])), Specificity = (tb3[2,2])/(sum(tb3[,2])))
# performance3 %>% kable(caption = "Performance evaluation on GSE46474", digits = 2)

df_nb = rbind(GSE51675.NB = performance1, GSE46474.NB = performance3)

rbind(df_lr, df_nb) %>% kable(caption = "Performance evaluation of NB and LR classifier on independent datasets", digit = 2)

final_model = final_nb
```

```{r fairness}
outcome = predict(final_model, combined_df %>% select(-outcome))
fairness_df = combined_df
fairness_df$predictions = outcome
acc_parity(data    = fairness_df, 
           outcome = 'outcome',
           outcome_base = 'Stable',
           preds = 'predictions',
           group   = 'sex',
           base    = 'Male')$Metric_plot
```

```{r stability_hyperparameters_tuning}
# for nb, no tuning applicable
```

```{r save}
emat2_unscaled <- exprs(gse2_cleaned) %>% log2()

clinical_df_unscaled = pdata2 %>% 
  select(c("description.1", "description.2")) %>% 
  rename("age" = "description.1",
         "sex" = "description.2") %>% 
  mutate(age = as.numeric(age_cleaned),
         sex = sex_cleaned)

combined_df_unscaled = cbind(clinical_df_unscaled, t(emat2_unscaled[top_genes, ])) %>% 
  mutate(outcome = as.factor(outcome2)) %>% 
  drop_na() %>% 
  mutate(sex = as.factor(sex))

combined_df_unscaled[, 3: (length(combined_df_unscaled) - 1)] = combined_df_unscaled[, 3: (length(combined_df_unscaled) - 1)] * (1 / length(top_genes))

save(gse3_cleaned, combined_df, final_model, combined_df_unscaled, file = "shiny.RData")
```